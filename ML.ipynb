{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция 3\n",
    "\n",
    "Типы пропусков: \n",
    "- отсуствует совершенно случайно MCAR\n",
    "- отсустсвует случайно MAR\n",
    "- отсустствует не случайно MNAR\n",
    "\n",
    "Обработка пропусков. \n",
    "Причины возникновения пропусков: \n",
    "- ошибка при сборе данных\n",
    "- сам источник неполный \n",
    "- данные могут быть доступны позже или не дотупны совсем \n",
    "- пропуски - это значения (имеют смысл) \n",
    "\n",
    "Методы обработки пропусков: \n",
    "- удаление. ИСпользуется когда пропуски случайны или нет связи с целевой переменной.\n",
    "- заполнение статистическими характеристиками (среднее, медиана, мода). \n",
    "- интерполяция/эстрполяция. Подходит к временным рядам (анализз данных относительно времени). \n",
    "    Интерполяция - способ нахождения значений между двумя неизвестыми значениями.\n",
    "    Экстаполяция - нахождение следующихзначений (предсказание будущего)\n",
    "- заполнение на основе корр. Подходит когда есть сильная взаимосвязь между признаками \n",
    "- заполнение на основе расстояния. \n",
    "- KNN - на основе k ближайших соседий. Выбирается точка для анализа, считается расстояние до других точек в данных, из всех точек выбираем k ближайших соседей. \n",
    "\n",
    "feature инженеринг - создание новых признаковдля улучшения модели машинного обучения \n",
    "\n",
    "Методы трансформации: \n",
    "- Интерактивные признаки (сильная взаимосвязь между переменными)\n",
    "- Масштабирование\n",
    "    - Стандартизация\n",
    "    - Преобразование в диапозон [0, 1] \n",
    "- Биннинг - процесс преобразования числового признака в категориальный. Полезно когда нужны выбросы и шумы\n",
    "- Трансформация в колонки. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лекция 4\n",
    "\n",
    "NLP - обработка естественного языка, посвященный тому, как компьютер анализирует человеческий язык.\n",
    "\n",
    "Области применения: \n",
    "- векторизация \n",
    "- классификация \n",
    "- выделение сущностей NER\n",
    "- группировка документов \n",
    "- распознование языков \n",
    "- генерация \n",
    "- и т.д.\n",
    "\n",
    "Этапы: \n",
    "- токенизаця (выделение абзацев, предложений, токенов)\n",
    "- морфологический анализ (определение начальной формы слов) \n",
    "- синтаксический анализ (определение связей между словами)\n",
    "- семантический анализ (определение смысла слова) \n",
    "\n",
    "Подготовка данных: \n",
    "- преобразование к одному регистру\n",
    "- удаление знаком препинания \n",
    "- удаление стоп-слов (междометия, частоиспольщуемые слова)\n",
    "- преобразовать в начальную форму\n",
    "\n",
    "обработанный текст - корпус \n",
    "\n",
    "Способы преобразования текста в матрецы-векторы: \n",
    "- countvectorizer\n",
    "- hashvectorizer\n",
    "- tfidfvectorizer\n",
    "\n",
    "каунтвекторайзер:\n",
    "Преимущества: \n",
    "- простота \n",
    "- возможность обратного переобразования \n",
    "Недостатки: \n",
    "- под большие данные не подойдет \n",
    "- разреженность матрицы \n",
    "- отсутствие семантики \n",
    "\n",
    "хэшвекторайзер: \n",
    "применяет хэш функцию для сокращения потребления памяти \n",
    "преимущества: \n",
    "- не требует памяти \n",
    "- фиксированный размер фич \n",
    "Недостатки: \n",
    "- разреженность \n",
    "- отсутствие семантики \n",
    "\n",
    "TF-IDF - сентаксическая мера, используемаядля оценки важности слова в контексте документа. \n",
    "С помощью IDF мы можем оценить, насколько уникально слово для корпуса. \n",
    "Преимущества: \n",
    "- есть учет важности слов в документе \n",
    "- общие слова получают меньший вес \n",
    "Недостатки: \n",
    "- вычистлительная сложность \n",
    "\n",
    "Корпус- очищенный текст. \n",
    "\n",
    "Общие недостатки: \n",
    "- нет семантики \n",
    "- разряженность матриц \n",
    "- не подходит длябольших корпусов \n",
    "- нет учета контекста \n",
    "\n",
    "WOrd2Vec - метод использует векторные представления так, что семантически близкие слова имеютболее близкий вектор \n",
    "\n",
    "BERT модели ещё сложнее\n",
    "\n",
    "pymorphy2 - библиотека для обработки слов и преобразования её нормальную форму\n",
    "\n",
    "Чем больше текст, тем разряженнее матрица. Это проблема. Для её решения хочеться сжать её:\n",
    "- Методы сокращения размерности\n",
    "- - Сокращение размерности\n",
    "- - Борьба с мултиколлинеарностю\n",
    "\n",
    "Зависимости Бывают:\n",
    "- Линейные\n",
    "- - Сохраняет структуру списков\n",
    "- Не линейные\n",
    "- - Меняем расположение книг. Оставляем расстояние между точками\n",
    "\n",
    "Методы преобразования\n",
    "- РСА\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
